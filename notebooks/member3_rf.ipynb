{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0aedf8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Member 3 â€” Random Forest Model\n",
    "# Diabetes Prediction Project (Supervised Learning)\n",
    "# =====================================================\n",
    "\n",
    "# ðŸ§  Objective:\n",
    "# Predict whether a person has diabetes (1) or not (0)\n",
    "# using the Pima Indians Diabetes Dataset.\n",
    "#\n",
    "# Model used here: Random Forest Classifier\n",
    "# -----------------------------------------------------\n",
    "# Works both on Local Machine and Google Colab\n",
    "# =====================================================\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Step 1: Import required libraries\n",
    "# -----------------------------------------------------\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    roc_curve, precision_recall_curve, average_precision_score\n",
    ")\n",
    "\n",
    "import joblib\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "MEMBER_NAME = \"member3_rf\"  # your personal folder name\n",
    "\n",
    "# Create folders (for your results)\n",
    "os.makedirs(f\"models/{MEMBER_NAME}\", exist_ok=True)\n",
    "os.makedirs(f\"reports/{MEMBER_NAME}/figures\", exist_ok=True)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Step 2: Load the dataset\n",
    "# -----------------------------------------------------\n",
    "# Adjust the path depending on your environment\n",
    "if os.path.exists(\"../data/raw/diabetes.csv\"):\n",
    "    data_path = \"../data/raw/diabetes.csv\"  # local path\n",
    "else:\n",
    "    data_path = \"diabetes.csv\"              # for Google Colab\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "print(\"âœ… Dataset loaded successfully!\")\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Step 3: Quick data understanding\n",
    "# -----------------------------------------------------\n",
    "print(\"\\nClass distribution (Outcome):\")\n",
    "print(df[\"Outcome\"].value_counts(normalize=True) * 100)\n",
    "\n",
    "sns.countplot(x=\"Outcome\", data=df)\n",
    "plt.title(\"Class Distribution (0 = Non-Diabetic, 1 = Diabetic)\")\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Step 4: Check for zeros that represent missing values\n",
    "# -----------------------------------------------------\n",
    "zero_counts = (df == 0).sum()\n",
    "print(\"\\nNumber of zero values in each column:\\n\", zero_counts)\n",
    "\n",
    "# Replace zeros with NaN for medical fields\n",
    "zero_missing = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "df[zero_missing] = df[zero_missing].replace(0, np.nan)\n",
    "\n",
    "print(\"\\nMissing values after replacement:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Step 5: Split the dataset into Train/Validation/Test\n",
    "# -----------------------------------------------------\n",
    "train, temp = train_test_split(df, test_size=0.3, stratify=df['Outcome'], random_state=RANDOM_STATE)\n",
    "val, test = train_test_split(temp, test_size=0.5, stratify=temp['Outcome'], random_state=RANDOM_STATE)\n",
    "\n",
    "print(f\"Train size: {len(train)}, Validation size: {len(val)}, Test size: {len(test)}\")\n",
    "\n",
    "feature_cols = [c for c in df.columns if c != 'Outcome']\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Step 6: Preprocess (impute missing + scale features)\n",
    "# -----------------------------------------------------\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(imputer.fit_transform(train[feature_cols]))\n",
    "X_val = scaler.transform(imputer.transform(val[feature_cols]))\n",
    "X_test = scaler.transform(imputer.transform(test[feature_cols]))\n",
    "\n",
    "y_train, y_val, y_test = train[\"Outcome\"], val[\"Outcome\"], test[\"Outcome\"]\n",
    "\n",
    "print(\"âœ… Preprocessing completed!\")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Step 7: Train a baseline Random Forest\n",
    "# -----------------------------------------------------\n",
    "rf_base = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    random_state=RANDOM_STATE,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_base.fit(X_train, y_train)\n",
    "\n",
    "y_val_pred = rf_base.predict(X_val)\n",
    "print(\"\\nðŸ”¹ Baseline Validation Performance:\\n\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Step 8: Hyperparameter tuning using RandomizedSearchCV\n",
    "# -----------------------------------------------------\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 500, 800],\n",
    "    'max_depth': [None, 5, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', 0.2, 0.5],\n",
    "    'class_weight': ['balanced', 'balanced_subsample']\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "rnd_search = RandomizedSearchCV(\n",
    "    rf_base,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=40,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=-1,\n",
    "    cv=cv,\n",
    "    random_state=RANDOM_STATE,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "print(\"\\nâ³ Running hyperparameter tuning (this may take a few minutes)...\")\n",
    "rnd_search.fit(X_train, y_train)\n",
    "\n",
    "best_rf = rnd_search.best_estimator_\n",
    "print(\"\\nâœ… Best Parameters Found:\")\n",
    "print(rnd_search.best_params_)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(best_rf, f\"../models/{MEMBER_NAME}/rf_best.joblib\")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Step 9: Evaluate the model on the Test set\n",
    "# -----------------------------------------------------\n",
    "y_test_proba = best_rf.predict_proba(X_test)[:, 1]\n",
    "y_test_pred = (y_test_proba >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\nðŸ”¹ Test Set Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_test_proba)\n",
    "ap_score = average_precision_score(y_test, y_test_proba)\n",
    "\n",
    "print(f\"ROC-AUC Score: {roc_auc:.3f}\")\n",
    "print(f\"Average Precision (PR AUC): {ap_score:.3f}\")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Step 10: Visualization - Confusion Matrix\n",
    "# -----------------------------------------------------\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix (Test Set)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.savefig(f\"../reports/{MEMBER_NAME}/figures/confusion_matrix.png\")\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Step 11: ROC Curve\n",
    "# -----------------------------------------------------\n",
    "fpr, tpr, _ = roc_curve(y_test, y_test_proba)\n",
    "plt.plot(fpr, tpr, label=f\"AUC={roc_auc:.3f}\")\n",
    "plt.plot([0, 1], [0, 1], \"--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - Random Forest (Member 3)\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"../reports/{MEMBER_NAME}/figures/roc_curve.png\")\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Step 12: Precision-Recall Curve\n",
    "# -----------------------------------------------------\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_test_proba)\n",
    "plt.plot(recall, precision, label=f\"AP={ap_score:.3f}\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve - Random Forest (Member 3)\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"../reports/{MEMBER_NAME}/figures/pr_curve.png\")\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Step 13: Feature Importances\n",
    "# -----------------------------------------------------\n",
    "importances = best_rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1][:10]\n",
    "plt.barh(np.array(feature_cols)[indices][::-1], importances[indices][::-1])\n",
    "plt.title(\"Top 10 Feature Importances - Random Forest (Member 3)\")\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.savefig(f\"../reports/{MEMBER_NAME}/figures/feature_importances.png\")\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Step 14: Save metrics summary\n",
    "# -----------------------------------------------------\n",
    "summary = {\n",
    "    \"roc_auc\": float(roc_auc),\n",
    "    \"average_precision\": float(ap_score),\n",
    "    \"best_params\": rnd_search.best_params_\n",
    "}\n",
    "pd.DataFrame([summary]).to_csv(f\"../reports/{MEMBER_NAME}/results_table.csv\", index=False)\n",
    "\n",
    "print(\"\\nâœ… Evaluation completed successfully!\")\n",
    "print(f\"All plots & results saved in: reports/{MEMBER_NAME}/\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
