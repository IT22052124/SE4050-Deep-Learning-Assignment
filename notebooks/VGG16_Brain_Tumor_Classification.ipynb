{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2fd784d",
   "metadata": {},
   "source": [
    "# Brain Tumor Classification with VGG16\n",
    "\n",
    "This notebook demonstrates brain tumor classification using VGG16 transfer learning.\n",
    "\n",
    "## Overview\n",
    "\n",
    "1. Mount Google Drive and set up environment\n",
    "2. Update repository and install dependencies\n",
    "3. Set up paths and configuration\n",
    "4. Preprocess the dataset\n",
    "5. Load and explore dataset\n",
    "6. Train VGG16 model\n",
    "7. Evaluate model performance\n",
    "8. Display results and make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aa51b4",
   "metadata": {},
   "source": [
    "## 1. Mount Google Drive and Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82caff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Verify TensorFlow and GPU availability\n",
    "import tensorflow as tf\n",
    "import platform\n",
    "\n",
    "print('TensorFlow version:', tf.__version__)\n",
    "print('Python version:', platform.python_version())\n",
    "print('GPUs available:', tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Set seed for reproducibility\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503f7554",
   "metadata": {},
   "source": [
    "## 2. Update Repository and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a9fb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to the main directory and install required packages\n",
    "%cd /content/drive/MyDrive/BrainTumor\n",
    "\n",
    "# Install required packages\n",
    "!pip install -q opencv-python\n",
    "!pip install -q scikit-learn\n",
    "!pip install -q matplotlib\n",
    "!pip install -q seaborn\n",
    "\n",
    "print(\"âœ… Dependencies installed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7c6d9a",
   "metadata": {},
   "source": [
    "## 3. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad1f4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import custom modules - assuming code is in BrainTumor directory\n",
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/BrainTumor')\n",
    "\n",
    "# If you have the src folder structure in BrainTumor, uncomment these:\n",
    "# from src.common.dataset_utils import create_datasets\n",
    "# from src.common.preprocessing import get_augmentation_pipeline, verify_dataset, split_and_copy\n",
    "# from src.common.gradcam import generate_gradcam\n",
    "\n",
    "print(\"âœ… All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3c602f",
   "metadata": {},
   "source": [
    "## 3.1. Import Custom Modules\n",
    "\n",
    "Import the required preprocessing and utility functions from the repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f6122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom modules from the repository\n",
    "from src.common.preprocess import create_dirs, split_and_copy, verify_dataset\n",
    "from src.common.preprocessing import count_samples_in_directory\n",
    "from src.models.vgg16.build_vgg16 import build_vgg16_model\n",
    "from src.models.vgg16.train_vgg16 import train_model\n",
    "from src.models.vgg16.evaluate_vgg16 import evaluate_model\n",
    "\n",
    "print(\"âœ… Custom modules imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48f9448",
   "metadata": {},
   "source": [
    "## 4. Setup Paths and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8e6087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - corrected paths for actual folder structure\n",
    "BASE_DIR = \"/content/drive/MyDrive/BrainTumor\"\n",
    "RAW_DATA_DIR = os.path.join(BASE_DIR, \"data\", \"archive\")  # Raw images are in BrainTumor/data/archive/\n",
    "PROCESSED_DATA_DIR = os.path.join(BASE_DIR, \"data\", \"processed\")\n",
    "RESULTS_DIR = os.path.join(BASE_DIR, \"Result\", \"vgg16\")\n",
    "\n",
    "# Model configuration - OPTIMIZED FOR SPEED\n",
    "INPUT_SHAPE = (224, 224, 3)  # VGG16 optimal input size\n",
    "BATCH_SIZE = 64  # Increased from 32 for faster training (if GPU memory allows)\n",
    "EPOCHS = 15  # Reduced from 20 - with early stopping, 15 is usually enough\n",
    "LEARNING_RATE = 0.001  # Slightly higher LR for faster convergence\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"âœ… OPTIMIZED Configuration:\")\n",
    "print(f\"   Base directory: {BASE_DIR}\")\n",
    "print(f\"   Raw data: {RAW_DATA_DIR}\")\n",
    "print(f\"   Processed data: {PROCESSED_DATA_DIR}\")\n",
    "print(f\"   Results: {RESULTS_DIR}\")\n",
    "print(f\"   Input shape: {INPUT_SHAPE}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE} (INCREASED for speed)\")\n",
    "print(f\"   Epochs: {EPOCHS} (REDUCED - early stopping will handle)\")\n",
    "print(f\"   Learning rate: {LEARNING_RATE} (OPTIMIZED)\")\n",
    "\n",
    "# Quick dataset size check for optimization\n",
    "yes_dir = os.path.join(RAW_DATA_DIR, \"yes\")\n",
    "no_dir = os.path.join(RAW_DATA_DIR, \"no\")\n",
    "\n",
    "if os.path.exists(yes_dir) and os.path.exists(no_dir):\n",
    "    yes_count = len([f for f in os.listdir(yes_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "    no_count = len([f for f in os.listdir(no_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "    total_images = yes_count + no_count\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Dataset Info:\")\n",
    "    print(f\"   Total images: {total_images}\")\n",
    "    print(f\"   Yes: {yes_count}, No: {no_count}\")\n",
    "    \n",
    "    # Calculate expected training time\n",
    "    train_images = int(total_images * 0.7)  # 70% for training\n",
    "    steps_per_epoch = train_images // BATCH_SIZE\n",
    "    print(f\"   Estimated steps per epoch: {steps_per_epoch}\")\n",
    "    \n",
    "    if steps_per_epoch > 100:\n",
    "        print(f\"   âš ï¸ Large dataset detected. Consider reducing epochs or increasing batch size.\")\n",
    "    else:\n",
    "        print(f\"   âœ… Good dataset size for efficient training.\")\n",
    "else:\n",
    "    print(f\"âš ï¸ Could not find raw data. Please check your Google Drive structure.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe7f7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance optimizations for faster training\n",
    "import tensorflow as tf\n",
    "\n",
    "# Enable mixed precision training (faster on modern GPUs)\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Configure GPU memory growth (prevents memory allocation issues)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"âœ… GPU memory growth enabled for {len(gpus)} GPU(s)\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"âš ï¸ GPU configuration error: {e}\")\n",
    "\n",
    "# Enable XLA compilation for faster training\n",
    "tf.config.optimizer.set_jit(True)\n",
    "\n",
    "# Optimize data pipeline\n",
    "tf.data.experimental.enable_debug_mode = False\n",
    "\n",
    "print(\"ðŸš€ Performance optimizations applied:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2189b8ef",
   "metadata": {},
   "source": [
    "### âš¡ Speed Optimization Tips\n",
    "\n",
    "**If training is still slow (>5 min/epoch), try these:**\n",
    "\n",
    "1. **Reduce Batch Size**: If you get memory errors with batch_size=64, try 32 or 16\n",
    "2. **Reduce Image Size**: Change INPUT_SHAPE to (128, 128, 3) for faster training\n",
    "3. **Use Colab Pro**: For faster GPU (T4/V100 instead of basic GPU)\n",
    "4. **Reduce Dataset**: Use a subset for initial testing\n",
    "5. **Check GPU Usage**: Run `!nvidia-smi` to verify GPU is being used\n",
    "\n",
    "**Expected Times:**\n",
    "- **Colab Free (K80)**: 5-10 min/epoch (normal)\n",
    "- **Colab Pro (T4/V100)**: 1-3 min/epoch (fast)\n",
    "- **CPU Only**: 20+ min/epoch (very slow - avoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a00f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick GPU and performance check\n",
    "print(\"ðŸ” Performance Check:\")\n",
    "print(f\"   TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# Check GPU availability and type\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"   âœ… GPU available: {len(gpus)} device(s)\")\n",
    "    \n",
    "    # Try to get GPU name (works in Colab)\n",
    "    try:\n",
    "        !nvidia-smi --query-gpu=name --format=csv,noheader,nounits\n",
    "    except:\n",
    "        print(\"   GPU info not available via nvidia-smi\")\n",
    "        \n",
    "    # Check if mixed precision is enabled\n",
    "    print(f\"   Mixed precision: {tf.keras.mixed_precision.global_policy().name}\")\n",
    "else:\n",
    "    print(\"   âŒ No GPU available - training will be VERY slow!\")\n",
    "    print(\"   ðŸ’¡ Enable GPU in Colab: Runtime > Change runtime type > Hardware accelerator > GPU\")\n",
    "\n",
    "# Memory check\n",
    "import psutil\n",
    "ram_gb = psutil.virtual_memory().total / (1024**3)\n",
    "print(f\"   Available RAM: {ram_gb:.1f} GB\")\n",
    "\n",
    "print(f\"\\nâ±ï¸ Expected training time per epoch:\")\n",
    "if gpus:\n",
    "    print(f\"   â€¢ With GPU: 2-8 minutes (normal)\")\n",
    "    print(f\"   â€¢ With optimization: 1-3 minutes (fast)\")\n",
    "else:\n",
    "    print(f\"   â€¢ Without GPU: 20+ minutes (too slow!)\")\n",
    "    \n",
    "print(f\"\\nðŸŽ¯ If still slow, reduce BATCH_SIZE to 32 or 16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5322a381",
   "metadata": {},
   "source": [
    "## 5. Data Preprocessing\n",
    "\n",
    "Check if preprocessing is needed and perform data preprocessing if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f864964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if preprocessing is needed\n",
    "train_dir = os.path.join(PROCESSED_DATA_DIR, \"train\")\n",
    "val_dir = os.path.join(PROCESSED_DATA_DIR, \"val\") \n",
    "test_dir = os.path.join(PROCESSED_DATA_DIR, \"test\")\n",
    "\n",
    "processed_exists, class_folders_valid = verify_dataset(PROCESSED_DATA_DIR)\n",
    "\n",
    "if processed_exists and class_folders_valid:\n",
    "    print(\"âœ… Processed data already exists. Skipping preprocessing.\")\n",
    "else:\n",
    "    print(\"ðŸ”„ Starting preprocessing...\")\n",
    "    \n",
    "    if os.path.exists(RAW_DATA_DIR):\n",
    "        total_files = split_and_copy(RAW_DATA_DIR, PROCESSED_DATA_DIR, [\"yes\", \"no\"])\n",
    "        print(f\"âœ… Preprocessing completed! Processed {total_files} images.\")\n",
    "    else:\n",
    "        print(\"âš ï¸ Raw data directory not found. Please check your Google Drive structure.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229ead79",
   "metadata": {},
   "source": [
    "## 6. Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4c7395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify processed data structure\n",
    "processed_exists, class_folders_valid = verify_dataset(PROCESSED_DATA_DIR)\n",
    "\n",
    "if processed_exists and class_folders_valid:\n",
    "    TRAIN_DATA_DIR = PROCESSED_DATA_DIR\n",
    "    print(f\"âœ… Using processed data: {TRAIN_DATA_DIR}\")\n",
    "else:\n",
    "    TRAIN_DATA_DIR = RAW_DATA_DIR\n",
    "    print(f\"âš ï¸ Using raw data: {TRAIN_DATA_DIR}\")\n",
    "\n",
    "# Display dataset statistics\n",
    "if processed_exists and class_folders_valid:\n",
    "    train_counts = count_samples_in_directory(os.path.join(PROCESSED_DATA_DIR, \"train\"))\n",
    "    val_counts = count_samples_in_directory(os.path.join(PROCESSED_DATA_DIR, \"val\"))\n",
    "    test_counts = count_samples_in_directory(os.path.join(PROCESSED_DATA_DIR, \"test\"))\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Dataset Statistics:\")\n",
    "    print(f\"   Training: {sum(train_counts.values())} images\")\n",
    "    print(f\"   Validation: {sum(val_counts.values())} images\")\n",
    "    print(f\"   Test: {sum(test_counts.values())} images\")\n",
    "    print(f\"   Classes: {list(train_counts.keys())}\")\n",
    "else:\n",
    "    print(f\"\\nðŸ“Š Using raw data structure with 'yes' and 'no' folders\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd18a2d",
   "metadata": {},
   "source": [
    "## 7. Build VGG16 Model Variants\n",
    "\n",
    "Create multiple VGG16 model variants for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df06874",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7. Train VGG16 Model\n",
    "\n",
    "Train the VGG16 model using the optimized training script:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b044d9c3",
   "metadata": {},
   "source": [
    "## 8. Train VGG16 Model\n",
    "\n",
    "Train the VGG16 model using the training script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d69b18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the VGG16 model\n",
    "print(\"Training VGG16 model...\")\n",
    "\n",
    "# Use the same approach as your friend's notebook - command line execution\n",
    "!python -m src.models.vgg16.train_vgg16 \\\n",
    "    --data_dir {TRAIN_DATA_DIR} \\\n",
    "    --results_dir {RESULTS_DIR} \\\n",
    "    --epochs 20 \\\n",
    "    --batch_size 32 \\\n",
    "    --img_size 224 224 \\\n",
    "    --use_processed {1 if processed_exists and class_folders_valid else 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013e82cf",
   "metadata": {},
   "source": [
    "## 9. Evaluate Model\n",
    "\n",
    "Evaluate the VGG16 model on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5cebd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "print(\"Evaluating VGG16 model...\")\n",
    "\n",
    "!python -m src.models.vgg16.evaluate_vgg16 \\\n",
    "    --data_dir {TRAIN_DATA_DIR} \\\n",
    "    --results_dir {RESULTS_DIR} \\\n",
    "    --batch_size 32 \\\n",
    "    --img_size 224 224 \\\n",
    "    --use_processed {1 if processed_exists and class_folders_valid else 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bfaa74",
   "metadata": {},
   "source": [
    "## 10. Display Results\n",
    "\n",
    "Show the training results and model performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8669f33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training history plot\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "try:\n",
    "    history_img = Image.open(f\"{RESULTS_DIR}/training_plot.png\")\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(history_img)\n",
    "    plt.axis('off')\n",
    "    plt.title('VGG16 Training History')\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error displaying training history: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b5739b",
   "metadata": {},
   "source": [
    "## 11. Display Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4758906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display confusion matrix\n",
    "try:\n",
    "    cm_img = Image.open(f\"{RESULTS_DIR}/confusion_matrix.png\")\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm_img)\n",
    "    plt.axis('off')\n",
    "    plt.title('VGG16 Confusion Matrix')\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error displaying confusion matrix: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484ac4d2",
   "metadata": {},
   "source": [
    "## 12. Display Classification Report and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5922d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display classification report\n",
    "try:\n",
    "    with open(f\"{RESULTS_DIR}/classification_report.txt\", 'r') as f:\n",
    "        report = f.read()\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "except Exception as e:\n",
    "    print(f\"Error reading classification report: {e}\")\n",
    "\n",
    "# Display metrics\n",
    "import json\n",
    "\n",
    "try:\n",
    "    with open(f\"{RESULTS_DIR}/metrics.json\", 'r') as f:\n",
    "        metrics = json.load(f)\n",
    "    print(\"\\nModel Metrics:\")\n",
    "    for metric, value in metrics.items():\n",
    "        if isinstance(value, (int, float)):\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "        else:\n",
    "            print(f\"{metric}: {value}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error reading metrics: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5351a0dc",
   "metadata": {},
   "source": [
    "## 13. Make Predictions\n",
    "\n",
    "Load the model and make predictions on sample images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd92856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# Load the best model\n",
    "try:\n",
    "    model_path = f\"{RESULTS_DIR}/best_model.h5\"\n",
    "    model = tf.keras.models.load_model(model_path, compile=False)\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    print(f\"âœ… Successfully loaded model from {model_path}\")\n",
    "    \n",
    "    # Load class names\n",
    "    try:\n",
    "        with open(f\"{RESULTS_DIR}/class_names.json\", 'r') as f:\n",
    "            class_names = json.load(f)\n",
    "    except:\n",
    "        class_names = [\"no\", \"yes\"]\n",
    "    \n",
    "    print(f\"Classes: {class_names}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "\n",
    "# Function to make predictions\n",
    "def predict_and_display(image_path):\n",
    "    # Load and preprocess image\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.io.decode_image(img, channels=3, expand_animations=False)\n",
    "    img = tf.image.resize(img, (224, 224))\n",
    "    img_display = img.numpy().astype(np.uint8)\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    img = tf.expand_dims(img, axis=0)\n",
    "    \n",
    "    # Make prediction\n",
    "    pred = model.predict(img, verbose=0)[0][0]\n",
    "    predicted_class = class_names[1] if pred > 0.5 else class_names[0]\n",
    "    confidence = pred if pred > 0.5 else 1 - pred\n",
    "    \n",
    "    # Display results\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img_display)\n",
    "    plt.title(f\"Prediction: {predicted_class} ({confidence:.2f})\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return predicted_class, confidence\n",
    "\n",
    "# Find sample images and make predictions\n",
    "test_yes_dir = os.path.join(PROCESSED_DATA_DIR, \"test\", \"yes\") \n",
    "test_no_dir = os.path.join(PROCESSED_DATA_DIR, \"test\", \"no\")\n",
    "\n",
    "sample_images = []\n",
    "\n",
    "# Get sample images\n",
    "if os.path.exists(test_yes_dir):\n",
    "    yes_files = os.listdir(test_yes_dir)[:2]\n",
    "    sample_images.extend([os.path.join(test_yes_dir, f) for f in yes_files])\n",
    "    \n",
    "if os.path.exists(test_no_dir):\n",
    "    no_files = os.listdir(test_no_dir)[:2]\n",
    "    sample_images.extend([os.path.join(test_no_dir, f) for f in no_files])\n",
    "\n",
    "# Fallback to raw data if processed not available\n",
    "if not sample_images:\n",
    "    if os.path.exists(os.path.join(RAW_DATA_DIR, \"yes\")):\n",
    "        yes_files = os.listdir(os.path.join(RAW_DATA_DIR, \"yes\"))[:2]\n",
    "        sample_images.extend([os.path.join(RAW_DATA_DIR, \"yes\", f) for f in yes_files])\n",
    "        \n",
    "    if os.path.exists(os.path.join(RAW_DATA_DIR, \"no\")):\n",
    "        no_files = os.listdir(os.path.join(RAW_DATA_DIR, \"no\"))[:2]\n",
    "        sample_images.extend([os.path.join(RAW_DATA_DIR, \"no\", f) for f in no_files])\n",
    "\n",
    "if sample_images:\n",
    "    print(f\"Making predictions on {len(sample_images)} sample images:\")\n",
    "    for img_path in sample_images:\n",
    "        true_class = \"yes\" if \"yes\" in img_path else \"no\"\n",
    "        pred_class, conf = predict_and_display(img_path)\n",
    "        print(f\"True: {true_class} | Predicted: {pred_class} | Confidence: {conf:.2f}\")\n",
    "else:\n",
    "    print(\"No sample images found for prediction.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b3d65b",
   "metadata": {},
   "source": [
    "## 14. Conclusion\n",
    "\n",
    "This notebook has successfully demonstrated VGG16 transfer learning for brain tumor classification with:\n",
    "\n",
    "- **VGG16 Model**: Pre-trained ImageNet weights with fine-tuned layers\n",
    "- **Efficient Training**: Using existing preprocessing and training scripts\n",
    "- **Comprehensive Evaluation**: Accuracy, precision, recall, F1-score metrics\n",
    "- **Minimal Code**: Clean, streamlined approach for easy comparison\n",
    "\n",
    "The model is now ready for comparison with other architectures like CNN, ResNet50, etc."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
