{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2fd784d",
   "metadata": {},
   "source": [
    "# Brain Tumor Classification with VGG16\n",
    "\n",
    "This notebook demonstrates an end-to-end workflow for brain tumor classification using VGG16 transfer learning models. It includes data preprocessing, multiple model variants, training, evaluation, and comprehensive result generation.\n",
    "\n",
    "## Overview\n",
    "\n",
    "1. Mount Google Drive and set up the environment\n",
    "2. Update the repository\n",
    "3. Install dependencies\n",
    "4. Set up paths to the dataset and results directories\n",
    "5. Load and explore the dataset\n",
    "6. Preprocess the data with augmentation\n",
    "7. Build multiple VGG16 model variants\n",
    "8. Train and validate all models\n",
    "9. Evaluate performance with comprehensive metrics\n",
    "10. Generate visualizations and save all required outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aa51b4",
   "metadata": {},
   "source": [
    "## 1. Mount Google Drive and Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82caff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Verify TensorFlow and GPU availability\n",
    "import tensorflow as tf\n",
    "import platform\n",
    "\n",
    "print('TensorFlow version:', tf.__version__)\n",
    "print('Python version:', platform.python_version())\n",
    "print('GPUs available:', tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Set seed for reproducibility\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503f7554",
   "metadata": {},
   "source": [
    "## 2. Update Repository and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a9fb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to the main directory and install required packages\n",
    "%cd /content/drive/MyDrive/BrainTumor\n",
    "\n",
    "# Install required packages\n",
    "!pip install -q opencv-python\n",
    "!pip install -q scikit-learn\n",
    "!pip install -q matplotlib\n",
    "!pip install -q seaborn\n",
    "\n",
    "print(\"✅ Dependencies installed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7c6d9a",
   "metadata": {},
   "source": [
    "## 3. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad1f4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import custom modules - assuming code is in BrainTumor directory\n",
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/BrainTumor')\n",
    "\n",
    "# If you have the src folder structure in BrainTumor, uncomment these:\n",
    "# from src.common.dataset_utils import create_datasets\n",
    "# from src.common.preprocessing import get_augmentation_pipeline, verify_dataset, split_and_copy\n",
    "# from src.common.gradcam import generate_gradcam\n",
    "\n",
    "print(\"✅ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3c602f",
   "metadata": {},
   "source": [
    "## 3.1. Define Utility Functions\n",
    "\n",
    "Since we're working directly from the BrainTumor directory, let's define the utility functions here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f6122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential utility functions for data processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import shutil\n",
    "\n",
    "def load_image_paths(data_dir, allowed_classes=None):\n",
    "    \"\"\"Scan a directory and collect image paths and labels.\"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    all_dirs = [p for p in data_dir.iterdir() if p.is_dir()]\n",
    "    \n",
    "    if allowed_classes:\n",
    "        classes = [c for c in allowed_classes if (data_dir / c).is_dir()]\n",
    "    else:\n",
    "        classes = sorted([p.name for p in all_dirs])\n",
    "\n",
    "    filepaths, labels = [], []\n",
    "    for cls in classes:\n",
    "        cls_dir = data_dir / cls\n",
    "        for img_path in cls_dir.glob('*'):\n",
    "            if img_path.suffix.lower() in ['.jpg', '.jpeg', '.png']:\n",
    "                filepaths.append(str(img_path))\n",
    "                labels.append(cls)\n",
    "    \n",
    "    print(f\"✅ Found {len(filepaths)} images in {classes}\")\n",
    "    return filepaths, labels, classes\n",
    "\n",
    "def create_splits(filepaths, labels, test_size=0.15, val_size=0.15, seed=42):\n",
    "    \"\"\"Create train/val/test splits.\"\"\"\n",
    "    t_files, te_files, t_labels, te_labels = train_test_split(\n",
    "        filepaths, labels, test_size=test_size, stratify=labels, random_state=seed\n",
    "    )\n",
    "    tr_files, va_files, tr_labels, va_labels = train_test_split(\n",
    "        t_files, t_labels, test_size=val_size/(1-test_size), stratify=t_labels, random_state=seed\n",
    "    )\n",
    "    \n",
    "    print(\"Split sizes:\", {'train': len(tr_files), 'val': len(va_files), 'test': len(te_files)})\n",
    "    print(\"Train label counts:\", dict(Counter(tr_labels)))\n",
    "    print(\"Val label counts:\", dict(Counter(va_labels)))\n",
    "    print(\"Test label counts:\", dict(Counter(te_labels)))\n",
    "    \n",
    "    return (tr_files, tr_labels), (va_files, va_labels), (te_files, te_labels)\n",
    "\n",
    "def copy_files_to_split_dir(files, labels, output_dir, split_name):\n",
    "    \"\"\"Copy files to train/val/test directories.\"\"\"\n",
    "    split_dir = Path(output_dir) / split_name\n",
    "    \n",
    "    for cls in set(labels):\n",
    "        cls_dir = split_dir / cls\n",
    "        cls_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for file_path, label in zip(files, labels):\n",
    "        src = Path(file_path)\n",
    "        dst = split_dir / label / src.name\n",
    "        shutil.copy2(src, dst)\n",
    "\n",
    "def split_and_copy(raw_dir, processed_dir, class_names):\n",
    "    \"\"\"Split raw data into train/val/test and copy to processed directory.\"\"\"\n",
    "    filepaths, labels, classes = load_image_paths(raw_dir, class_names)\n",
    "    \n",
    "    if len(filepaths) == 0:\n",
    "        print(\"⚠️ No images found!\")\n",
    "        return 0\n",
    "    \n",
    "    train_data, val_data, test_data = create_splits(filepaths, labels)\n",
    "    \n",
    "    # Copy files to respective directories\n",
    "    copy_files_to_split_dir(train_data[0], train_data[1], processed_dir, \"train\")\n",
    "    copy_files_to_split_dir(val_data[0], val_data[1], processed_dir, \"val\")\n",
    "    copy_files_to_split_dir(test_data[0], test_data[1], processed_dir, \"test\")\n",
    "    \n",
    "    return len(filepaths)\n",
    "\n",
    "def verify_dataset(data_dir):\n",
    "    \"\"\"Verify if processed dataset exists with correct structure.\"\"\"\n",
    "    data_path = Path(data_dir)\n",
    "    \n",
    "    if not data_path.exists():\n",
    "        return False, False\n",
    "    \n",
    "    required_dirs = [\"train\", \"val\", \"test\"]\n",
    "    required_classes = [\"yes\", \"no\"]\n",
    "    \n",
    "    for split in required_dirs:\n",
    "        split_dir = data_path / split\n",
    "        if not split_dir.exists():\n",
    "            return False, False\n",
    "        \n",
    "        for cls in required_classes:\n",
    "            cls_dir = split_dir / cls\n",
    "            if not cls_dir.exists():\n",
    "                return False, False\n",
    "    \n",
    "    return True, True\n",
    "\n",
    "def get_augmentation_pipeline():\n",
    "    \"\"\"Get data augmentation pipeline.\"\"\"\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "        tf.keras.layers.RandomRotation(0.1),\n",
    "        tf.keras.layers.RandomZoom(0.1),\n",
    "    ])\n",
    "\n",
    "def load_and_preprocess_image(path, label, img_size):\n",
    "    \"\"\"Load and preprocess a single image with error handling.\"\"\"\n",
    "    try:\n",
    "        # Read and decode image\n",
    "        image = tf.io.read_file(path)\n",
    "        image = tf.image.decode_image(image, channels=3, expand_animations=False)\n",
    "        \n",
    "        # Ensure the image has a defined shape\n",
    "        image = tf.ensure_shape(image, [None, None, 3])\n",
    "        \n",
    "        # Resize image\n",
    "        image = tf.image.resize(image, img_size)\n",
    "        \n",
    "        # Normalize to [0, 1]\n",
    "        image = tf.cast(image, tf.float32) / 255.0\n",
    "        \n",
    "        return image, label\n",
    "    except Exception as e:\n",
    "        # If image loading fails, return a black image\n",
    "        print(f\"Warning: Could not load image {path}, using placeholder\")\n",
    "        black_image = tf.zeros((*img_size, 3), dtype=tf.float32)\n",
    "        return black_image, label\n",
    "\n",
    "def create_tf_dataset(file_paths, labels, class_names, batch_size, img_size, is_training=False, augment_fn=None):\n",
    "    \"\"\"Create TensorFlow dataset from file paths and labels.\"\"\"\n",
    "    # Convert string labels to integers\n",
    "    label_to_int = {name: i for i, name in enumerate(class_names)}\n",
    "    int_labels = [label_to_int[label] for label in labels]\n",
    "    \n",
    "    # Create dataset\n",
    "    ds = tf.data.Dataset.from_tensor_slices((file_paths, int_labels))\n",
    "    \n",
    "    # Map the load and preprocess function\n",
    "    ds = ds.map(\n",
    "        lambda path, label: load_and_preprocess_image(path, label, img_size),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    \n",
    "    # Filter out any None values (corrupted images)\n",
    "    ds = ds.filter(lambda image, label: tf.reduce_all(tf.math.is_finite(image)))\n",
    "    \n",
    "    if is_training and augment_fn is not None:\n",
    "        ds = ds.map(lambda x, y: (augment_fn(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return ds\n",
    "\n",
    "def create_datasets(data_dir, batch_size, img_size=(224, 224), augment_fn=None):\n",
    "    \"\"\"Create train/val/test datasets from processed directory.\"\"\"\n",
    "    data_path = Path(data_dir)\n",
    "    \n",
    "    # Get class names\n",
    "    train_dir = data_path / \"train\"\n",
    "    class_names = sorted([d.name for d in train_dir.iterdir() if d.is_dir()])\n",
    "    \n",
    "    datasets = {}\n",
    "    \n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        split_dir = data_path / split\n",
    "        file_paths = []\n",
    "        labels = []\n",
    "        \n",
    "        for cls in class_names:\n",
    "            cls_dir = split_dir / cls\n",
    "            for img_path in cls_dir.glob(\"*\"):\n",
    "                if img_path.suffix.lower() in ['.jpg', '.jpeg', '.png']:\n",
    "                    file_paths.append(str(img_path))\n",
    "                    labels.append(cls)\n",
    "        \n",
    "        print(f\"Found {len(file_paths)} images in {split} set\")\n",
    "        \n",
    "        is_training = (split == \"train\")\n",
    "        datasets[split] = create_tf_dataset(\n",
    "            file_paths, labels, class_names, batch_size, img_size, is_training, augment_fn\n",
    "        )\n",
    "    \n",
    "    return datasets[\"train\"], datasets[\"val\"], datasets[\"test\"], class_names\n",
    "\n",
    "print(\"✅ Utility functions defined successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671f30e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Grad-CAM implementation\n",
    "def generate_gradcam(model, dataset, save_dir, class_names, num_images=3, max_samples=2):\n",
    "    \"\"\"Generate simple Grad-CAM visualizations.\"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Generating Grad-CAM visualizations (limited to {num_images} images)...\")\n",
    "    \n",
    "    # Get a batch of images\n",
    "    for batch_num, (images, labels) in enumerate(dataset.take(max_samples)):\n",
    "        if batch_num >= max_samples:\n",
    "            break\n",
    "            \n",
    "        for i in range(min(num_images, len(images))):\n",
    "            try:\n",
    "                img = images[i:i+1]\n",
    "                \n",
    "                # Find the last convolutional layer\n",
    "                last_conv_layer = None\n",
    "                for layer in reversed(model.layers):\n",
    "                    if len(layer.output_shape) == 4:  # Conv layer has 4D output\n",
    "                        last_conv_layer = layer\n",
    "                        break\n",
    "                \n",
    "                if last_conv_layer is None:\n",
    "                    print(\"No convolutional layer found\")\n",
    "                    continue\n",
    "                \n",
    "                # Create a model that maps the input image to the activations of the last conv layer\n",
    "                grad_model = tf.keras.models.Model(\n",
    "                    inputs=[model.inputs],\n",
    "                    outputs=[last_conv_layer.output, model.output]\n",
    "                )\n",
    "                \n",
    "                # Compute the gradient of the predicted class for our input image\n",
    "                with tf.GradientTape() as tape:\n",
    "                    conv_outputs, predictions = grad_model(img)\n",
    "                    loss = predictions[0, 0]  # For binary classification\n",
    "                \n",
    "                # Extract gradients\n",
    "                grads = tape.gradient(loss, conv_outputs)\n",
    "                \n",
    "                # Pool the gradients over all the axes leaving out the channel dimension\n",
    "                pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "                \n",
    "                # Weight the channels by the corresponding gradients\n",
    "                conv_outputs = conv_outputs[0]\n",
    "                heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "                heatmap = tf.squeeze(heatmap)\n",
    "                \n",
    "                # Normalize the heatmap\n",
    "                heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "                \n",
    "                # Create the visualization\n",
    "                img_display = images[i].numpy()\n",
    "                \n",
    "                plt.figure(figsize=(12, 4))\n",
    "                \n",
    "                plt.subplot(1, 3, 1)\n",
    "                plt.imshow(img_display)\n",
    "                plt.title('Original Image')\n",
    "                plt.axis('off')\n",
    "                \n",
    "                plt.subplot(1, 3, 2)\n",
    "                plt.imshow(heatmap, cmap='jet')\n",
    "                plt.title('Grad-CAM Heatmap')\n",
    "                plt.axis('off')\n",
    "                \n",
    "                plt.subplot(1, 3, 3)\n",
    "                # Resize heatmap to image size\n",
    "                heatmap_resized = tf.image.resize(heatmap[..., tf.newaxis], img_display.shape[:2])\n",
    "                heatmap_resized = tf.squeeze(heatmap_resized)\n",
    "                \n",
    "                plt.imshow(img_display)\n",
    "                plt.imshow(heatmap_resized, cmap='jet', alpha=0.4)\n",
    "                plt.title('Overlay')\n",
    "                plt.axis('off')\n",
    "                \n",
    "                # Save the visualization\n",
    "                filename = f\"gradcam_batch{batch_num}_img{i}.png\"\n",
    "                plt.savefig(os.path.join(save_dir, filename), dpi=150, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error generating Grad-CAM for image {i}: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    print(f\"✅ Grad-CAM visualizations saved to {save_dir}\")\n",
    "\n",
    "print(\"✅ Grad-CAM function defined successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48f9448",
   "metadata": {},
   "source": [
    "## 4. Setup Paths and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8e6087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - corrected paths for actual folder structure\n",
    "BASE_DIR = \"/content/drive/MyDrive/BrainTumor\"\n",
    "RAW_DATA_DIR = os.path.join(BASE_DIR, \"data\", \"archive\")  # Raw images are in BrainTumor/data/archive/\n",
    "PROCESSED_DATA_DIR = os.path.join(BASE_DIR, \"data\", \"processed\")\n",
    "RESULTS_DIR = os.path.join(BASE_DIR, \"Result\", \"vgg16\")\n",
    "\n",
    "# Model configuration\n",
    "INPUT_SHAPE = (224, 224, 3)  # VGG16 optimal input size\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.join(RESULTS_DIR, \"gradcam\"), exist_ok=True)\n",
    "\n",
    "print(f\"✅ Paths configured:\")\n",
    "print(f\"   Base directory: {BASE_DIR}\")\n",
    "print(f\"   Raw data: {RAW_DATA_DIR}\")\n",
    "print(f\"   Processed data: {PROCESSED_DATA_DIR}\")\n",
    "print(f\"   Results: {RESULTS_DIR}\")\n",
    "print(f\"   Input shape: {INPUT_SHAPE}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Epochs: {EPOCHS}\")\n",
    "\n",
    "# Verify the raw data structure exists\n",
    "yes_dir = os.path.join(RAW_DATA_DIR, \"yes\")\n",
    "no_dir = os.path.join(RAW_DATA_DIR, \"no\")\n",
    "\n",
    "print(f\"\\n🔍 Checking raw data structure:\")\n",
    "print(f\"   Raw data directory exists: {os.path.exists(RAW_DATA_DIR)}\")\n",
    "print(f\"   Yes folder exists: {os.path.exists(yes_dir)}\")\n",
    "print(f\"   No folder exists: {os.path.exists(no_dir)}\")\n",
    "\n",
    "if os.path.exists(yes_dir):\n",
    "    yes_count = len([f for f in os.listdir(yes_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "    print(f\"   Images in yes folder: {yes_count}\")\n",
    "\n",
    "if os.path.exists(no_dir):\n",
    "    no_count = len([f for f in os.listdir(no_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "    print(f\"   Images in no folder: {no_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5322a381",
   "metadata": {},
   "source": [
    "## 5. Data Preprocessing\n",
    "\n",
    "Check if preprocessing is needed and perform data preprocessing if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f864964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if processed data exists\n",
    "train_dir = os.path.join(PROCESSED_DATA_DIR, \"train\")\n",
    "val_dir = os.path.join(PROCESSED_DATA_DIR, \"val\")\n",
    "test_dir = os.path.join(PROCESSED_DATA_DIR, \"test\")\n",
    "\n",
    "processed_exists, class_folders_valid = verify_dataset(PROCESSED_DATA_DIR)\n",
    "\n",
    "if processed_exists and class_folders_valid:\n",
    "    print(\"✅ Processed data already exists with valid class folders. Skipping preprocessing.\")\n",
    "else:\n",
    "    print(\"🔄 Starting preprocessing...\")\n",
    "    print(f\"Reading raw images from: {RAW_DATA_DIR}\")\n",
    "    print(f\"Saving processed images to: {PROCESSED_DATA_DIR}\")\n",
    "\n",
    "    # Check if raw data exists\n",
    "    yes_dir = os.path.join(RAW_DATA_DIR, \"yes\")\n",
    "    no_dir = os.path.join(RAW_DATA_DIR, \"no\")\n",
    "    \n",
    "    if os.path.exists(RAW_DATA_DIR) and os.path.exists(yes_dir) and os.path.exists(no_dir):\n",
    "        total_files = split_and_copy(RAW_DATA_DIR, PROCESSED_DATA_DIR, [\"yes\", \"no\"])\n",
    "        print(f\"✅ Preprocessing completed successfully! Processed {total_files} images.\")\n",
    "    else:\n",
    "        print(\"⚠️  Could not find expected yes/no folders in the raw data directory.\")\n",
    "        print(\"Please make sure your Google Drive contains the correct folder structure.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229ead79",
   "metadata": {},
   "source": [
    "## 6. Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4c7395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets with data augmentation for VGG16 (224x224 input)\n",
    "augment = get_augmentation_pipeline()\n",
    "train_ds, val_ds, test_ds, class_names = create_datasets(\n",
    "    PROCESSED_DATA_DIR, \n",
    "    BATCH_SIZE, \n",
    "    img_size=(224, 224),  # VGG16 optimal size\n",
    "    augment_fn=augment\n",
    ")\n",
    "\n",
    "print(f\"✅ Dataset loaded successfully!\")\n",
    "print(f\"   Class names: {class_names}\")\n",
    "print(f\"   Input shape: {INPUT_SHAPE}\")\n",
    "\n",
    "# Display sample images\n",
    "plt.figure(figsize=(12, 8))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(min(9, len(images))):\n",
    "        plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(f\"Class: {class_names[int(labels[i])]}\")\n",
    "        plt.axis('off')\n",
    "plt.suptitle(\"Sample Images from Training Dataset\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RESULTS_DIR, \"sample_images.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Dataset statistics\n",
    "train_samples = sum(1 for _ in train_ds.unbatch())\n",
    "val_samples = sum(1 for _ in val_ds.unbatch())\n",
    "test_samples = sum(1 for _ in test_ds.unbatch())\n",
    "\n",
    "print(f\"\\n📊 Dataset Statistics:\")\n",
    "print(f\"   Training samples: {train_samples}\")\n",
    "print(f\"   Validation samples: {val_samples}\")\n",
    "print(f\"   Test samples: {test_samples}\")\n",
    "print(f\"   Total samples: {train_samples + val_samples + test_samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd18a2d",
   "metadata": {},
   "source": [
    "## 7. Build VGG16 Model Variants\n",
    "\n",
    "Create multiple VGG16 model variants for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df06874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vgg16_model(input_shape=INPUT_SHAPE):\n",
    "    \"\"\"\n",
    "    Optimized VGG16 transfer learning model for brain tumor classification\n",
    "    Uses fine-tuning approach for best performance\n",
    "    \"\"\"\n",
    "    # Load pre-trained VGG16 model\n",
    "    base_model = VGG16(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=input_shape\n",
    "    )\n",
    "    \n",
    "    # Fine-tuning: Freeze early layers, unfreeze last block for better feature learning\n",
    "    base_model.trainable = True\n",
    "    for layer in base_model.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Build the complete model\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(1, activation='sigmoid')  # Binary classification\n",
    "    ])\n",
    "    \n",
    "    # Compile with lower learning rate for fine-tuning\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE/10),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build the VGG16 model\n",
    "print(\"🏗️ Building VGG16 model...\")\n",
    "vgg16_model = build_vgg16_model()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"📋 VGG16 Model Summary\")\n",
    "print(f\"{'='*60}\")\n",
    "vgg16_model.summary()\n",
    "\n",
    "# Save model summary\n",
    "with open(os.path.join(RESULTS_DIR, \"VGG16_model_summary.txt\"), \"w\") as f:\n",
    "    vgg16_model.summary(print_fn=lambda x: f.write(x + \"\\n\"))\n",
    "\n",
    "print(f\"\\n✅ VGG16 model created successfully!\")\n",
    "print(f\"   Total parameters: {vgg16_model.count_params():,}\")\n",
    "print(f\"   Trainable parameters: {sum([tf.keras.backend.count_params(w) for w in vgg16_model.trainable_weights]):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b044d9c3",
   "metadata": {},
   "source": [
    "## 8. Model Training and Validation\n",
    "\n",
    "Train the VGG16 model and track its performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d69b18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_vgg16_model(model, epochs=EPOCHS):\n",
    "    \"\"\"Train the VGG16 model with callbacks and return history\"\"\"\n",
    "    \n",
    "    # Create model directory\n",
    "    model_dir = os.path.join(RESULTS_DIR, \"VGG16\")\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    # Callbacks for training optimization\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(\n",
    "            filepath=os.path.join(model_dir, \"VGG16_best.h5\"),\n",
    "            monitor=\"val_accuracy\",\n",
    "            save_best_only=True,\n",
    "            mode='max',\n",
    "            verbose=1\n",
    "        ),\n",
    "        EarlyStopping(\n",
    "            monitor=\"val_loss\", \n",
    "            patience=5, \n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\n🚀 Training VGG16 model...\")\n",
    "    print(f\"   Epochs: {epochs}\")\n",
    "    print(f\"   Model directory: {model_dir}\")\n",
    "    print(f\"   Callbacks: ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\")\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ VGG16 training completed!\")\n",
    "    print(f\"   Best validation accuracy: {max(history.history['val_accuracy']):.4f}\")\n",
    "    print(f\"   Total epochs trained: {len(history.history['accuracy'])}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Train the VGG16 model\n",
    "print(\"=\"*70)\n",
    "print(\"🎯 Starting VGG16 Model Training\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "vgg16_history = train_vgg16_model(vgg16_model)\n",
    "\n",
    "print(f\"\\n🎉 VGG16 model training completed successfully!\")\n",
    "print(f\"   Final training accuracy: {vgg16_history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"   Final validation accuracy: {vgg16_history.history['val_accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013e82cf",
   "metadata": {},
   "source": [
    "## 9. Generate Training Plots\n",
    "\n",
    "Create and save training history plots for the VGG16 model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5cebd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive training plots for VGG16\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('VGG16 Model Training Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Training and validation accuracy\n",
    "ax1.plot(vgg16_history.history['accuracy'], label='Training Accuracy', color='blue', linewidth=2)\n",
    "ax1.plot(vgg16_history.history['val_accuracy'], label='Validation Accuracy', color='red', linewidth=2)\n",
    "ax1.set_title('Model Accuracy', fontweight='bold')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Training and validation loss\n",
    "ax2.plot(vgg16_history.history['loss'], label='Training Loss', color='blue', linewidth=2)\n",
    "ax2.plot(vgg16_history.history['val_loss'], label='Validation Loss', color='red', linewidth=2)\n",
    "ax2.set_title('Model Loss', fontweight='bold')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Learning rate (if available)\n",
    "if 'lr' in vgg16_history.history:\n",
    "    ax3.plot(vgg16_history.history['lr'], color='green', linewidth=2)\n",
    "    ax3.set_title('Learning Rate Schedule', fontweight='bold')\n",
    "    ax3.set_xlabel('Epoch')\n",
    "    ax3.set_ylabel('Learning Rate')\n",
    "    ax3.set_yscale('log')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "else:\n",
    "    # Show accuracy difference instead\n",
    "    train_acc = vgg16_history.history['accuracy']\n",
    "    val_acc = vgg16_history.history['val_accuracy']\n",
    "    acc_diff = [t - v for t, v in zip(train_acc, val_acc)]\n",
    "    ax3.plot(acc_diff, color='purple', linewidth=2)\n",
    "    ax3.set_title('Training-Validation Accuracy Gap', fontweight='bold')\n",
    "    ax3.set_xlabel('Epoch')\n",
    "    ax3.set_ylabel('Accuracy Difference')\n",
    "    ax3.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Epoch-wise improvement\n",
    "epochs = range(1, len(vgg16_history.history['val_accuracy']) + 1)\n",
    "val_acc_improvement = [0] + [vgg16_history.history['val_accuracy'][i] - vgg16_history.history['val_accuracy'][i-1] \n",
    "                             for i in range(1, len(vgg16_history.history['val_accuracy']))]\n",
    "ax4.bar(epochs, val_acc_improvement, color='orange', alpha=0.7)\n",
    "ax4.set_title('Validation Accuracy Improvement per Epoch', fontweight='bold')\n",
    "ax4.set_xlabel('Epoch')\n",
    "ax4.set_ylabel('Accuracy Improvement')\n",
    "ax4.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RESULTS_DIR, \"training_analysis.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Create the main training plot (for comparison with friend's model)\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(vgg16_history.history['accuracy'], label='Training', linewidth=2, color='blue')\n",
    "plt.plot(vgg16_history.history['val_accuracy'], label='Validation', linewidth=2, color='red')\n",
    "plt.title('VGG16 Model Accuracy', fontweight='bold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(vgg16_history.history['loss'], label='Training', linewidth=2, color='blue')\n",
    "plt.plot(vgg16_history.history['val_loss'], label='Validation', linewidth=2, color='red')\n",
    "plt.title('VGG16 Model Loss', fontweight='bold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('VGG16 Brain Tumor Classification - Training History', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RESULTS_DIR, \"training_plot.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print training summary\n",
    "print(\"📊 Training Summary:\")\n",
    "print(f\"   Final Training Accuracy: {vgg16_history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"   Final Validation Accuracy: {vgg16_history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"   Best Validation Accuracy: {max(vgg16_history.history['val_accuracy']):.4f}\")\n",
    "print(f\"   Final Training Loss: {vgg16_history.history['loss'][-1]:.4f}\")\n",
    "print(f\"   Final Validation Loss: {vgg16_history.history['val_loss'][-1]:.4f}\")\n",
    "print(f\"   Total Epochs: {len(vgg16_history.history['accuracy'])}\")\n",
    "\n",
    "print(\"✅ Training plots generated and saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bfaa74",
   "metadata": {},
   "source": [
    "## 10. Model Evaluation and Metrics\n",
    "\n",
    "Evaluate the VGG16 model on the test set and generate comprehensive metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8669f33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model weights\n",
    "best_model_path = os.path.join(RESULTS_DIR, \"VGG16\", \"VGG16_best.h5\")\n",
    "if os.path.exists(best_model_path):\n",
    "    vgg16_model.load_weights(best_model_path)\n",
    "    print(\"✅ Loaded best model weights\")\n",
    "else:\n",
    "    print(\"⚠️ Best model weights not found, using current weights\")\n",
    "\n",
    "# Evaluate VGG16 model on test set\n",
    "print(f\"\\n📊 Evaluating VGG16 model on test set...\")\n",
    "\n",
    "# Get predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_pred_proba = []\n",
    "\n",
    "print(\"🔄 Generating predictions...\")\n",
    "for images, labels in test_ds:\n",
    "    predictions = vgg16_model.predict(images, verbose=0)\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred_proba.extend(predictions.flatten())\n",
    "    y_pred.extend((predictions > 0.5).astype(int).flatten())\n",
    "\n",
    "# Calculate comprehensive metrics\n",
    "test_accuracy = accuracy_score(y_true, y_pred)\n",
    "test_precision = precision_score(y_true, y_pred)\n",
    "test_recall = recall_score(y_true, y_pred)\n",
    "test_f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# Get training metrics\n",
    "train_acc = max(vgg16_history.history['accuracy'])\n",
    "val_acc = max(vgg16_history.history['val_accuracy'])\n",
    "train_loss = min(vgg16_history.history['loss'])\n",
    "val_loss = min(vgg16_history.history['val_loss'])\n",
    "\n",
    "# Create comprehensive metrics dictionary\n",
    "vgg16_metrics = {\n",
    "    'model_name': 'VGG16_Brain_Tumor_Classifier',\n",
    "    'model_type': 'Transfer Learning (Fine-tuned)',\n",
    "    'architecture': 'VGG16 + Custom Classifier',\n",
    "    'train_accuracy': float(train_acc),\n",
    "    'val_accuracy': float(val_acc),\n",
    "    'test_accuracy': float(test_accuracy),\n",
    "    'train_loss': float(train_loss),\n",
    "    'val_loss': float(val_loss),\n",
    "    'test_precision': float(test_precision),\n",
    "    'test_recall': float(test_recall),\n",
    "    'test_f1_score': float(test_f1),\n",
    "    'epochs_trained': len(vgg16_history.history['accuracy']),\n",
    "    'total_parameters': int(vgg16_model.count_params()),\n",
    "    'trainable_parameters': int(sum([tf.keras.backend.count_params(w) for w in vgg16_model.trainable_weights]))\n",
    "}\n",
    "\n",
    "# Display results\n",
    "print(f\"\\n🎯 VGG16 Model Performance Results:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"📈 Training Metrics:\")\n",
    "print(f\"   Best Training Accuracy: {train_acc:.4f}\")\n",
    "print(f\"   Best Validation Accuracy: {val_acc:.4f}\")\n",
    "print(f\"   Best Training Loss: {train_loss:.4f}\")\n",
    "print(f\"   Best Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "print(f\"\\n🎯 Test Set Performance:\")\n",
    "print(f\"   Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"   Test Precision: {test_precision:.4f}\")\n",
    "print(f\"   Test Recall: {test_recall:.4f}\")\n",
    "print(f\"   Test F1-Score: {test_f1:.4f}\")\n",
    "\n",
    "print(f\"\\n🏗️ Model Configuration:\")\n",
    "print(f\"   Total Parameters: {vgg16_metrics['total_parameters']:,}\")\n",
    "print(f\"   Trainable Parameters: {vgg16_metrics['trainable_parameters']:,}\")\n",
    "print(f\"   Epochs Trained: {vgg16_metrics['epochs_trained']}\")\n",
    "\n",
    "# Save individual model metrics\n",
    "with open(os.path.join(RESULTS_DIR, \"VGG16_metrics.json\"), \"w\") as f:\n",
    "    json.dump(vgg16_metrics, f, indent=4)\n",
    "\n",
    "print(f\"\\n✅ Model evaluation completed!\")\n",
    "print(f\"📁 Metrics saved to: VGG16_metrics.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b5739b",
   "metadata": {},
   "source": [
    "## 11. Create Confusion Matrix\n",
    "\n",
    "Generate confusion matrix and classification report for the VGG16 model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4758906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix for VGG16 model\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Create confusion matrix display\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "\n",
    "plt.title('VGG16 Brain Tumor Classification - Confusion Matrix', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RESULTS_DIR, \"confusion_matrix.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Generate detailed classification report\n",
    "classification_report_text = classification_report(y_true, y_pred, target_names=class_names)\n",
    "print(f\"\\n📋 VGG16 Classification Report:\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report_text)\n",
    "\n",
    "# Save classification report\n",
    "with open(os.path.join(RESULTS_DIR, \"classification_report.txt\"), \"w\") as f:\n",
    "    f.write(\"VGG16 Brain Tumor Classification - Detailed Report\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\\n\")\n",
    "    f.write(\"Model: VGG16 Transfer Learning (Fine-tuned)\\n\")\n",
    "    f.write(f\"Test Accuracy: {test_accuracy:.4f}\\n\")\n",
    "    f.write(f\"Test F1-Score: {test_f1:.4f}\\n\\n\")\n",
    "    f.write(\"Classification Report:\\n\")\n",
    "    f.write(\"-\"*50 + \"\\n\")\n",
    "    f.write(classification_report_text)\n",
    "    f.write(\"\\n\\nConfusion Matrix:\\n\")\n",
    "    f.write(\"-\"*20 + \"\\n\")\n",
    "    f.write(f\"True Negatives (no): {cm[0,0]}\\n\")\n",
    "    f.write(f\"False Positives (no→yes): {cm[0,1]}\\n\")\n",
    "    f.write(f\"False Negatives (yes→no): {cm[1,0]}\\n\")\n",
    "    f.write(f\"True Positives (yes): {cm[1,1]}\\n\")\n",
    "\n",
    "# Create a detailed metrics visualization\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('VGG16 Model Performance Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Metrics bar chart\n",
    "metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "metrics_values = [test_accuracy, test_precision, test_recall, test_f1]\n",
    "colors = ['skyblue', 'lightcoral', 'lightgreen', 'gold']\n",
    "\n",
    "bars = ax1.bar(metrics_names, metrics_values, color=colors, alpha=0.8)\n",
    "ax1.set_title('Test Set Metrics', fontweight='bold')\n",
    "ax1.set_ylabel('Score')\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars, metrics_values):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "             f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Training vs Validation comparison\n",
    "train_val_metrics = ['Training Acc', 'Validation Acc', 'Training Loss', 'Validation Loss']\n",
    "train_values = [train_acc, val_acc, train_loss, val_loss]\n",
    "x_pos = np.arange(len(train_val_metrics[:2]))\n",
    "\n",
    "ax2.bar(x_pos, [train_acc, val_acc], color=['blue', 'red'], alpha=0.7)\n",
    "ax2.set_title('Training vs Validation Accuracy', fontweight='bold')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(['Training', 'Validation'])\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate([train_acc, val_acc]):\n",
    "    ax2.text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Prediction distribution\n",
    "ax3.hist(y_pred_proba, bins=30, alpha=0.7, color='purple', edgecolor='black')\n",
    "ax3.axvline(x=0.5, color='red', linestyle='--', linewidth=2, label='Decision Threshold')\n",
    "ax3.set_title('Prediction Probability Distribution', fontweight='bold')\n",
    "ax3.set_xlabel('Predicted Probability')\n",
    "ax3.set_ylabel('Frequency')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Confusion matrix as heatmap\n",
    "im = ax4.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "ax4.set_title('Confusion Matrix Heatmap', fontweight='bold')\n",
    "tick_marks = np.arange(len(class_names))\n",
    "ax4.set_xticks(tick_marks)\n",
    "ax4.set_yticks(tick_marks)\n",
    "ax4.set_xticklabels(class_names)\n",
    "ax4.set_yticklabels(class_names)\n",
    "ax4.set_ylabel('True Label')\n",
    "ax4.set_xlabel('Predicted Label')\n",
    "\n",
    "# Add text annotations\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in np.ndindex(cm.shape):\n",
    "    ax4.text(j, i, format(cm[i, j], 'd'),\n",
    "             ha=\"center\", va=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "             fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RESULTS_DIR, \"performance_analysis.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Confusion matrix and performance analysis generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484ac4d2",
   "metadata": {},
   "source": [
    "## 12. Generate Grad-CAM Visualizations\n",
    "\n",
    "Create Grad-CAM visualizations to understand what the VGG16 model focuses on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5922d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Grad-CAM visualizations for the VGG16 model\n",
    "print(f\"🔍 Generating Grad-CAM visualizations for VGG16 model...\")\n",
    "\n",
    "# Create gradcam directory\n",
    "gradcam_dir = os.path.join(RESULTS_DIR, \"gradcam\")\n",
    "os.makedirs(gradcam_dir, exist_ok=True)\n",
    "\n",
    "# Generate Grad-CAM for VGG16 model\n",
    "try:\n",
    "    generate_gradcam(\n",
    "        model=vgg16_model, \n",
    "        dataset=test_ds, \n",
    "        save_dir=gradcam_dir, \n",
    "        class_names=class_names,\n",
    "        num_images=5,  # Generate for 5 images\n",
    "        max_samples=3   # Limit to first 3 batches for speed\n",
    "    )\n",
    "    print(\"✅ Grad-CAM visualizations generated successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️  Grad-CAM generation failed: {str(e)}\")\n",
    "    print(\"Continuing without Grad-CAM...\")\n",
    "\n",
    "# Create a comprehensive sample predictions visualization\n",
    "plt.figure(figsize=(20, 15))\n",
    "sample_count = 0\n",
    "max_samples = 16\n",
    "\n",
    "print(\"📸 Creating sample predictions visualization...\")\n",
    "\n",
    "for images, labels in test_ds.take(3):  # Take 3 batches\n",
    "    predictions = vgg16_model.predict(images, verbose=0)\n",
    "    \n",
    "    for i in range(min(len(images), max_samples - sample_count)):\n",
    "        if sample_count >= max_samples:\n",
    "            break\n",
    "            \n",
    "        plt.subplot(4, 4, sample_count + 1)\n",
    "        plt.imshow(images[i].numpy())\n",
    "        \n",
    "        true_label = class_names[int(labels[i])]\n",
    "        pred_prob = predictions[i][0]\n",
    "        pred_label = class_names[1] if pred_prob > 0.5 else class_names[0]\n",
    "        confidence = pred_prob if pred_prob > 0.5 else (1 - pred_prob)\n",
    "        \n",
    "        # Color based on correctness\n",
    "        color = 'green' if true_label == pred_label else 'red'\n",
    "        \n",
    "        plt.title(f'True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.3f}', \n",
    "                 color=color, fontsize=12, fontweight='bold')\n",
    "        plt.axis('off')\n",
    "        sample_count += 1\n",
    "    \n",
    "    if sample_count >= max_samples:\n",
    "        break\n",
    "\n",
    "plt.suptitle('VGG16 Model - Sample Predictions on Test Set', fontsize=18, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RESULTS_DIR, \"sample_predictions.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Create prediction confidence analysis\n",
    "correct_predictions = [i for i, (true, pred) in enumerate(zip(y_true, y_pred)) if true == pred]\n",
    "incorrect_predictions = [i for i, (true, pred) in enumerate(zip(y_true, y_pred)) if true != pred]\n",
    "\n",
    "correct_confidences = [y_pred_proba[i] if y_pred[i] == 1 else 1-y_pred_proba[i] for i in correct_predictions]\n",
    "incorrect_confidences = [y_pred_proba[i] if y_pred[i] == 1 else 1-y_pred_proba[i] for i in incorrect_predictions]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(correct_confidences, bins=20, alpha=0.7, color='green', label=f'Correct ({len(correct_predictions)})')\n",
    "plt.hist(incorrect_confidences, bins=20, alpha=0.7, color='red', label=f'Incorrect ({len(incorrect_predictions)})')\n",
    "plt.xlabel('Prediction Confidence')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Prediction Confidence Distribution', fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "accuracy_by_confidence = []\n",
    "confidence_bins = np.arange(0.5, 1.01, 0.05)\n",
    "\n",
    "for i in range(len(confidence_bins)-1):\n",
    "    lower, upper = confidence_bins[i], confidence_bins[i+1]\n",
    "    indices = [j for j, conf in enumerate([y_pred_proba[k] if y_pred[k] == 1 else 1-y_pred_proba[k] \n",
    "                                          for k in range(len(y_pred))]) \n",
    "              if lower <= conf < upper]\n",
    "    \n",
    "    if indices:\n",
    "        bin_accuracy = sum(y_true[j] == y_pred[j] for j in indices) / len(indices)\n",
    "        accuracy_by_confidence.append(bin_accuracy)\n",
    "    else:\n",
    "        accuracy_by_confidence.append(0)\n",
    "\n",
    "plt.plot(confidence_bins[:-1], accuracy_by_confidence, 'bo-', linewidth=2, markersize=8)\n",
    "plt.xlabel('Confidence Bin')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Prediction Confidence', fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim(0, 1.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RESULTS_DIR, \"confidence_analysis.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Sample predictions and confidence analysis completed!\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n📊 Prediction Analysis Summary:\")\n",
    "print(f\"   Total test samples: {len(y_true)}\")\n",
    "print(f\"   Correct predictions: {len(correct_predictions)} ({len(correct_predictions)/len(y_true)*100:.1f}%)\")\n",
    "print(f\"   Incorrect predictions: {len(incorrect_predictions)} ({len(incorrect_predictions)/len(y_true)*100:.1f}%)\")\n",
    "print(f\"   Average confidence (correct): {np.mean(correct_confidences):.3f}\")\n",
    "print(f\"   Average confidence (incorrect): {np.mean(incorrect_confidences):.3f}\")\n",
    "print(f\"   High confidence correct (>0.9): {sum(1 for c in correct_confidences if c > 0.9)}\")\n",
    "print(f\"   High confidence incorrect (>0.9): {sum(1 for c in incorrect_confidences if c > 0.9)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5351a0dc",
   "metadata": {},
   "source": [
    "## 13. Save Model and Final Results\n",
    "\n",
    "Save the VGG16 model and generate all required output files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd92856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the VGG16 model as best_model.h5\n",
    "best_model_path = os.path.join(RESULTS_DIR, \"best_model.h5\")\n",
    "vgg16_model.save(best_model_path)\n",
    "print(f\"✅ VGG16 model saved as: {best_model_path}\")\n",
    "\n",
    "# Save comprehensive metrics for easy comparison with your friend's models\n",
    "final_metrics = {\n",
    "    \"model_name\": \"VGG16_Brain_Tumor_Classifier\",\n",
    "    \"model_type\": \"Transfer Learning (Fine-tuned VGG16)\",\n",
    "    \"architecture_details\": {\n",
    "        \"base_model\": \"VGG16 (ImageNet pre-trained)\",\n",
    "        \"fine_tuning\": \"Last 4 layers unfrozen\",\n",
    "        \"classifier\": \"GAP + Dense(512) + BN + Dropout(0.5) + Dense(256) + Dropout(0.3) + Dense(1)\",\n",
    "        \"input_shape\": INPUT_SHAPE,\n",
    "        \"total_parameters\": vgg16_metrics['total_parameters'],\n",
    "        \"trainable_parameters\": vgg16_metrics['trainable_parameters']\n",
    "    },\n",
    "    \"training_config\": {\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"epochs_trained\": vgg16_metrics['epochs_trained'],\n",
    "        \"initial_learning_rate\": LEARNING_RATE/10,  # Fine-tuning LR\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"loss_function\": \"binary_crossentropy\",\n",
    "        \"callbacks\": [\"ModelCheckpoint\", \"EarlyStopping\", \"ReduceLROnPlateau\"]\n",
    "    },\n",
    "    \"performance_metrics\": {\n",
    "        \"train_accuracy\": vgg16_metrics['train_accuracy'],\n",
    "        \"val_accuracy\": vgg16_metrics['val_accuracy'],\n",
    "        \"test_accuracy\": vgg16_metrics['test_accuracy'],\n",
    "        \"test_precision\": vgg16_metrics['test_precision'],\n",
    "        \"test_recall\": vgg16_metrics['test_recall'],\n",
    "        \"test_f1_score\": vgg16_metrics['test_f1_score'],\n",
    "        \"train_loss\": vgg16_metrics['train_loss'],\n",
    "        \"val_loss\": vgg16_metrics['val_loss']\n",
    "    },\n",
    "    \"dataset_info\": {\n",
    "        \"class_names\": class_names,\n",
    "        \"train_samples\": train_samples,\n",
    "        \"val_samples\": val_samples,\n",
    "        \"test_samples\": test_samples,\n",
    "        \"total_samples\": train_samples + val_samples + test_samples,\n",
    "        \"class_distribution\": \"Binary classification: yes/no for brain tumor presence\"\n",
    "    },\n",
    "    \"comparison_ready\": {\n",
    "        \"accuracy\": vgg16_metrics['test_accuracy'],\n",
    "        \"f1_score\": vgg16_metrics['test_f1_score'],\n",
    "        \"precision\": vgg16_metrics['test_precision'],\n",
    "        \"recall\": vgg16_metrics['test_recall'],\n",
    "        \"model_size_mb\": os.path.getsize(best_model_path) / (1024*1024) if os.path.exists(best_model_path) else 0\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save the comprehensive metrics\n",
    "with open(os.path.join(RESULTS_DIR, \"metrics.json\"), \"w\") as f:\n",
    "    json.dump(final_metrics, f, indent=4)\n",
    "\n",
    "print(f\"✅ Comprehensive metrics saved: {os.path.join(RESULTS_DIR, 'metrics.json')}\")\n",
    "\n",
    "# Generate final summary report for easy comparison\n",
    "summary_report = f\"\"\"# VGG16 Brain Tumor Classification - Final Results\n",
    "\n",
    "## 🎯 Model Performance Summary\n",
    "- **Model**: VGG16 Transfer Learning (Fine-tuned)\n",
    "- **Test Accuracy**: {vgg16_metrics['test_accuracy']:.4f} ({vgg16_metrics['test_accuracy']*100:.2f}%)\n",
    "- **Test Precision**: {vgg16_metrics['test_precision']:.4f}\n",
    "- **Test Recall**: {vgg16_metrics['test_recall']:.4f}\n",
    "- **Test F1-Score**: {vgg16_metrics['test_f1_score']:.4f}\n",
    "\n",
    "## 📊 Comparison Metrics (for your friend's comparison)\n",
    "```\n",
    "Accuracy:  {vgg16_metrics['test_accuracy']:.4f}\n",
    "F1-Score:  {vgg16_metrics['test_f1_score']:.4f}\n",
    "Precision: {vgg16_metrics['test_precision']:.4f}\n",
    "Recall:    {vgg16_metrics['test_recall']:.4f}\n",
    "```\n",
    "\n",
    "## 🏗️ Model Architecture\n",
    "- **Base Model**: VGG16 (ImageNet pre-trained)\n",
    "- **Fine-tuning**: Last 4 layers unfrozen\n",
    "- **Classifier**: Custom head with BatchNorm and Dropout\n",
    "- **Parameters**: {vgg16_metrics['total_parameters']:,} total ({vgg16_metrics['trainable_parameters']:,} trainable)\n",
    "\n",
    "## 🎮 Training Configuration\n",
    "- **Epochs Trained**: {vgg16_metrics['epochs_trained']}\n",
    "- **Batch Size**: {BATCH_SIZE}\n",
    "- **Learning Rate**: {LEARNING_RATE/10} (fine-tuning)\n",
    "- **Optimizer**: Adam\n",
    "- **Callbacks**: EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "## 📁 Generated Files\n",
    "- `best_model.h5` - Trained VGG16 model\n",
    "- `training_plot.png` - Training history visualization\n",
    "- `confusion_matrix.png` - Model performance matrix\n",
    "- `metrics.json` - Comprehensive metrics data\n",
    "- `gradcam/` - Grad-CAM visualizations\n",
    "- `classification_report.txt` - Detailed performance report\n",
    "\n",
    "## 📈 Dataset Information\n",
    "- **Classes**: {class_names}\n",
    "- **Training Samples**: {train_samples:,}\n",
    "- **Validation Samples**: {val_samples:,}\n",
    "- **Test Samples**: {test_samples:,}\n",
    "- **Total Samples**: {train_samples + val_samples + test_samples:,}\n",
    "\n",
    "---\n",
    "*Generated for comparison with other deep learning models*\n",
    "\"\"\"\n",
    "\n",
    "with open(os.path.join(RESULTS_DIR, \"summary_report.md\"), \"w\") as f:\n",
    "    f.write(summary_report)\n",
    "\n",
    "print(\"✅ Summary report generated!\")\n",
    "\n",
    "# List all generated files for verification\n",
    "print(f\"\\n📁 Generated files in {RESULTS_DIR}:\")\n",
    "for item in sorted(os.listdir(RESULTS_DIR)):\n",
    "    item_path = os.path.join(RESULTS_DIR, item)\n",
    "    if os.path.isfile(item_path):\n",
    "        size_mb = os.path.getsize(item_path) / (1024*1024)\n",
    "        print(f\"   📄 {item} ({size_mb:.1f} MB)\")\n",
    "    elif os.path.isdir(item_path):\n",
    "        print(f\"   📁 {item}/\")\n",
    "        for subfile in sorted(os.listdir(item_path)):\n",
    "            subfile_path = os.path.join(item_path, subfile)\n",
    "            if os.path.isfile(subfile_path):\n",
    "                size_mb = os.path.getsize(subfile_path) / (1024*1024)\n",
    "                print(f\"      📄 {subfile} ({size_mb:.1f} MB)\")\n",
    "\n",
    "# Final performance summary\n",
    "print(f\"\\n🎉 VGG16 Brain Tumor Classification completed successfully!\")\n",
    "print(f\"=\"*70)\n",
    "print(f\"🏆 FINAL RESULTS:\")\n",
    "print(f\"   Model: VGG16 Transfer Learning\")\n",
    "print(f\"   Test Accuracy: {vgg16_metrics['test_accuracy']:.4f} ({vgg16_metrics['test_accuracy']*100:.2f}%)\")\n",
    "print(f\"   Test F1-Score: {vgg16_metrics['test_f1_score']:.4f}\")\n",
    "print(f\"   Model Size: {final_metrics['comparison_ready']['model_size_mb']:.1f} MB\")\n",
    "print(f\"   Training Time: {vgg16_metrics['epochs_trained']} epochs\")\n",
    "print(f\"=\"*70)\n",
    "print(f\"📁 All results saved in: {RESULTS_DIR}\")\n",
    "print(f\"📊 Ready for comparison with your friend's models!\")\n",
    "\n",
    "# Create a simple comparison table for easy reference\n",
    "comparison_table = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],\n",
    "    'VGG16_Score': [\n",
    "        f\"{vgg16_metrics['test_accuracy']:.4f}\",\n",
    "        f\"{vgg16_metrics['test_precision']:.4f}\",\n",
    "        f\"{vgg16_metrics['test_recall']:.4f}\",\n",
    "        f\"{vgg16_metrics['test_f1_score']:.4f}\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(f\"\\n\udccb Quick Comparison Table:\")\n",
    "print(comparison_table.to_string(index=False))\n",
    "\n",
    "# Save comparison table\n",
    "comparison_table.to_csv(os.path.join(RESULTS_DIR, \"comparison_metrics.csv\"), index=False)\n",
    "print(f\"\\n✅ Comparison table saved as: comparison_metrics.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
