{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ca9d0ed",
   "metadata": {},
   "source": [
    "## Optimized Evaluation (Faster Version)\n",
    "\n",
    "If the standard evaluation script takes too long to run, you can use this faster version that limits the number of images used for ROC curves and Grad-CAM visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca386ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faster evaluation script that limits the number of images processed\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from PIL import Image\n",
    "\n",
    "# Function to generate quicker GradCAM visualization\n",
    "def quick_gradcam(model, img, save_path=None):\n",
    "    # Find last Conv2D layer\n",
    "    last_conv_layer = None\n",
    "    for layer in reversed(model.layers):\n",
    "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "            last_conv_layer = layer\n",
    "            break\n",
    "    \n",
    "    if last_conv_layer is None:\n",
    "        print(\"No Conv2D layer found!\")\n",
    "        return None\n",
    "    \n",
    "    # Create a model that outputs both the last conv layer and the final output\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        inputs=[model.inputs],\n",
    "        outputs=[last_conv_layer.output, model.output]\n",
    "    )\n",
    "    \n",
    "    # Expand dimensions for batch\n",
    "    img_array = tf.expand_dims(img, axis=0)\n",
    "    \n",
    "    # Get gradients\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        class_out = preds[:, 0]\n",
    "    \n",
    "    # Gradients of the output with respect to the last conv layer\n",
    "    grads = tape.gradient(class_out, last_conv_layer_output)\n",
    "    \n",
    "    # Pooled gradients\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    \n",
    "    # Weight the channels by the gradients\n",
    "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
    "    pooled_grads = pooled_grads.numpy()\n",
    "    \n",
    "    # Apply weights\n",
    "    for i in range(pooled_grads.shape[-1]):\n",
    "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
    "        \n",
    "    # Average over channels\n",
    "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
    "    \n",
    "    # ReLU\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    \n",
    "    # Normalize\n",
    "    if np.max(heatmap) > 0:\n",
    "        heatmap = heatmap / np.max(heatmap)\n",
    "    \n",
    "    # Resize to original image size\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = tf.image.resize(\n",
    "        tf.expand_dims(heatmap, -1),\n",
    "        (img.shape[0], img.shape[1])\n",
    "    ).numpy().squeeze()\n",
    "    \n",
    "    # Convert image to RGB numpy array\n",
    "    img_np = img.numpy()\n",
    "    if img_np.max() <= 1.0:\n",
    "        img_np = img_np * 255\n",
    "    img_np = img_np.astype(np.uint8)\n",
    "    \n",
    "    # Create heatmap\n",
    "    cmap = plt.get_cmap('jet')\n",
    "    colored_heatmap = cmap(heatmap)[:, :, :3]\n",
    "    colored_heatmap = (colored_heatmap * 255).astype(np.uint8)\n",
    "    \n",
    "    # Combine original and heatmap\n",
    "    superimposed_img = cv2.addWeighted(img_np, 0.6, colored_heatmap, 0.4, 0)\n",
    "    \n",
    "    if save_path:\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(superimposed_img)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "    \n",
    "    return superimposed_img\n",
    "\n",
    "# Load the model\n",
    "model_path = f\"{RESULTS_DIR}/best_model.h5\"\n",
    "if not os.path.exists(model_path):\n",
    "    model_path = f\"{RESULTS_DIR}/model.h5\"\n",
    "\n",
    "print(f\"Loading model from: {model_path}\")\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "model.summary()\n",
    "\n",
    "# Create a faster dataset with a smaller batch for testing\n",
    "batch_size = 32\n",
    "img_size = (224, 224)\n",
    "\n",
    "# Use processed data structure\n",
    "test_dir = os.path.join(PROCESSED_DATA_DIR, 'test')\n",
    "if os.path.exists(test_dir):\n",
    "    print(f\"Loading test data from: {test_dir}\")\n",
    "    \n",
    "    # Create the test dataset with a smaller batch\n",
    "    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Limit the evaluation to just a few batches\n",
    "    max_batches = 5\n",
    "    print(f\"Using only {max_batches} batches for faster evaluation\")\n",
    "    \n",
    "    # Get predictions for a limited number of batches\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_scores = []\n",
    "    \n",
    "    # Process limited batches for confusion matrix\n",
    "    print(\"Generating predictions for confusion matrix...\")\n",
    "    for i, (images, labels) in enumerate(test_generator):\n",
    "        if i >= max_batches:\n",
    "            break\n",
    "            \n",
    "        # Get predictions\n",
    "        scores = model.predict(images, verbose=0)\n",
    "        preds = (scores > 0.5).astype(int)\n",
    "        \n",
    "        # Store results\n",
    "        y_true.extend(labels)\n",
    "        y_pred.extend(preds.flatten())\n",
    "        y_scores.extend(scores.flatten())\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_scores = np.array(y_scores)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = np.mean(y_true == y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    # Add labels\n",
    "    class_names = ['No Tumor', 'Tumor']\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    \n",
    "    # Add values to the plot\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                    horizontalalignment=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig(os.path.join(RESULTS_DIR, \"confusion_matrix_fast.png\"))\n",
    "    plt.show()\n",
    "    \n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(os.path.join(RESULTS_DIR, \"roc_curve_fast.png\"))\n",
    "    plt.show()\n",
    "    \n",
    "    # Precision-Recall Curve\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
    "    avg_precision = average_precision_score(y_true, y_scores)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, color='blue', lw=2, label=f'Precision-Recall curve (AP = {avg_precision:.2f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.savefig(os.path.join(RESULTS_DIR, \"pr_curve_fast.png\"))\n",
    "    plt.show()\n",
    "    \n",
    "    # Generate a few GradCAM visualizations (just 2 for speed)\n",
    "    print(\"Generating limited GradCAM visualizations...\")\n",
    "    gradcam_dir = os.path.join(RESULTS_DIR, \"gradcam_fast\")\n",
    "    os.makedirs(gradcam_dir, exist_ok=True)\n",
    "    \n",
    "    # Get a batch of test images\n",
    "    test_batch = next(test_generator)\n",
    "    test_images = test_batch[0]\n",
    "    test_labels = test_batch[1]\n",
    "    \n",
    "    # Process just 2 images\n",
    "    for i in range(2):\n",
    "        if i < len(test_images):\n",
    "            img = test_images[i]\n",
    "            label = test_labels[i]\n",
    "            pred = model.predict(np.expand_dims(img, 0), verbose=0)[0][0]\n",
    "            pred_label = 1 if pred > 0.5 else 0\n",
    "            \n",
    "            # Create a filename with info\n",
    "            filename = f\"gradcam_fast_{i}_true_{class_names[int(label)]}_pred_{class_names[pred_label]}_{pred:.2f}.png\"\n",
    "            save_path = os.path.join(gradcam_dir, filename)\n",
    "            \n",
    "            # Generate and save GradCAM\n",
    "            try:\n",
    "                import cv2\n",
    "                _ = quick_gradcam(model, img, save_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating GradCAM: {e}\")\n",
    "    \n",
    "    print(\"Fast evaluation completed!\")\n",
    "else:\n",
    "    print(\"Could not find test directory. Make sure to run preprocessing first.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
